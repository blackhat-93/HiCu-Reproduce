{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackhat-93/HiCu-Reproduce/blob/dryrun_colab/Colab_Cuong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below assumes that you have:\n",
        "- Cloned the entire github repo to a folder called `HiCu-Reproduce` at the root of your Google Drive\n",
        "- Completed the data preprocessing steps described in `README.md`\n",
        "- Copied the resulting data into the sub-folder `data`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGGdfXIhcZGW"
      },
      "source": [
        "# Pip libraries setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICVPVRnucgcI"
      },
      "outputs": [],
      "source": [
        "# # No need to run this cell\n",
        "# # Saved here as a record of package versions that worked off-the-shelf from Colab on 20Nov2023\n",
        "\n",
        "# # Colab's python version was 3.10.12\n",
        "# !pip install gensim==4.3.2\n",
        "# !pip install nltk==3.8.1\n",
        "# !pip install numpy==1.23.5\n",
        "# !pip install pandas==1.5.3\n",
        "# !pip install scikit-learn==1.2.2\n",
        "# !pip install scipy==1.11.3\n",
        "# !pip install tqdm==4.66.1\n",
        "# !pip install transformers==4.35.2\n",
        "# !pip install packaging==23.2\n",
        "# !pip install torch==2.1.0+cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb1UQ7fKm_cH"
      },
      "source": [
        "# Check package versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSWRu3-YlTEF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import gensim\n",
        "import nltk\n",
        "import numpy\n",
        "import pandas\n",
        "import sklearn\n",
        "import scipy\n",
        "import tqdm\n",
        "import transformers\n",
        "import packaging\n",
        "import torch\n",
        "\n",
        "print(\"python:\", sys.version)\n",
        "print(\"gensim:\", gensim.__version__)\n",
        "print(\"nltk:\", nltk.__version__)\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"pandas:\", pandas.__version__)\n",
        "print(\"scikit-learn:\", sklearn.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n",
        "print(\"tqdm:\", tqdm.__version__)\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"packaging:\", packaging.__version__)\n",
        "print(\"torch:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KonzJON3oKd0"
      },
      "source": [
        "# Check CUDA & RAM availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVq9m_tnIzN"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU: \" + torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0AbBrCG16vJ"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5StNPQCxmFtY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "num_cores = os.cpu_count()\n",
        "print(\"Number of CPU cores:\", num_cores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqGnPqDoUHCz"
      },
      "source": [
        "# Transfer data to Google Colab local drive (faster training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG-V0JQ9mN9M"
      },
      "outputs": [],
      "source": [
        "# Give access to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy Google Drive to Google Colab local drive\n",
        "!cp -r '/content/drive/My Drive/HiCu-Reproduce' '/content/'\n",
        "\n",
        "# Change directory to HiCu-Reproduce folder in Google Colab\n",
        "import os\n",
        "os.chdir('/content/HiCu-Reproduce')\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Content of current directory:\", os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLbLcyM5moKq"
      },
      "source": [
        "# Run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZT8EWYfmU-p"
      },
      "outputs": [],
      "source": [
        "# NOTE: Change the name of the .py training script to your desired model configuration\n",
        "!python runs/run_multirescnn_hicua_asl_full.py\n",
        "\n",
        "# Save results back to google drive\n",
        "!cp -r '/content/HiCu-Reproduce/models' '/content/drive/My Drive/HiCu-Reproduce'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPvT3mjxEjQFEcgKzpw1t4o",
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
